{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Comprehensive Air Quality Data EDA - Multan AQI Features\n",
        "\n",
        "This notebook completes the comprehensive analysis of engineered air quality and weather data from Hopsworks feature store.\n",
        "\n",
        "## Dataset Overview\n",
        "- **Source**: Hopsworks Feature Store (multan_aqi_features)\n",
        "- **Records**: 905 observations \n",
        "- **Features**: 127 engineered features\n",
        "- **Time Range**: June 2025 - July 2025\n",
        "\n",
        "## Modeling Approach\n",
        "- **üéØ Goal**: Accurate US AQI prediction for Multan\n",
        "- **üîß Method**: Train ML model to predict PM2.5 & PM10 ‚Üí Calculate AQI via EPA formula\n",
        "- **üìä ML Targets**: pm2_5, pm10 concentrations (¬µg/m¬≥)\n",
        "- **‚úÖ Success Metric**: How well calculated AQI matches actual AQI values\n",
        "\n",
        "## Feature Categories\n",
        "1. **Raw Air Quality**: pm2_5, pm10, co, no, no2, so2, o3, nh3\n",
        "2. **AQI Calculations**: pm2_5_aqi, pm10_aqi, us_aqi\n",
        "3. **Weather Data**: temperature, humidity, pressure, wind_speed, wind_direction\n",
        "4. **Time Features**: Cyclical encodings (hour, day, month, etc.)\n",
        "5. **Lag Features**: 1h-72h historical values\n",
        "6. **Rolling Statistics**: 3h-24h windows (mean, std, min, max)\n",
        "7. **Engineered Features**: Interactions, squared terms, categorical flags\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Data Overview\n",
        "Loading and examining the basic structure of our modeling dataset from Hopsworks.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import hopsworks\n",
        "from datetime import datetime, timedelta\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Import configuration\n",
        "from config import HOPSWORKS_CONFIG\n",
        "\n",
        "# Set plotting style\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "plt.rcParams['figure.figsize'] = (12, 8)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Connect to Hopsworks and load data\n",
        "print(\"Connecting to Hopsworks...\")\n",
        "project = hopsworks.login(api_key_value=HOPSWORKS_CONFIG[\"api_key\"], project=HOPSWORKS_CONFIG[\"project_name\"])\n",
        "fs = project.get_feature_store()\n",
        "\n",
        "print(\"Loading feature group data...\")\n",
        "fg = fs.get_feature_group(HOPSWORKS_CONFIG[\"feature_group_name\"], version=1)\n",
        "df = fg.read()\n",
        "\n",
        "print(f\"Successfully loaded {len(df)} records from Hopsworks\")\n",
        "print(f\"Date range: {df['time'].min()} to {df['time'].max()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fix column references and prepare data\n",
        "print(\"Data preparation and column check...\")\n",
        "print(f\"Time column: {'time' if 'time' in df.columns else 'timestamp not found'}\")\n",
        "print(f\"Date range: {df['time'].min()} to {df['time'].max()}\")\n",
        "\n",
        "# Ensure time is datetime\n",
        "if df['time'].dtype == 'object':\n",
        "    df['time'] = pd.to_datetime(df['time'])\n",
        "\n",
        "# Sort by time\n",
        "df = df.sort_values('time').reset_index(drop=True)\n",
        "print(\"‚úì Data sorted by time\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Rolling Features Analysis\n",
        "\n",
        "**Focus**: Analyzing 32 rolling statistics features (16 for PM2.5 + 16 for PM10) to determine their predictive value and optimal usage.\n",
        "\n",
        "### 9.1 Rolling Features Overview\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 9.1 Rolling Features Overview\n",
        "print(\"=\" * 60)\n",
        "print(\"ROLLING FEATURES ANALYSIS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Identify all rolling features\n",
        "pm25_rolling = [col for col in df.columns if 'rolling' in col and 'pm2_5' in col]\n",
        "pm10_rolling = [col for col in df.columns if 'rolling' in col and 'pm10' in col]\n",
        "all_rolling = pm25_rolling + pm10_rolling\n",
        "\n",
        "print(f\"Total Rolling Features: {len(all_rolling)}\")\n",
        "print(f\"PM2.5 Rolling Features: {len(pm25_rolling)}\")\n",
        "print(f\"PM10 Rolling Features: {len(pm10_rolling)}\")\n",
        "\n",
        "# Categorize by window size and statistic\n",
        "windows = ['3h', '6h', '12h', '24h']\n",
        "stats = ['mean', 'std', 'min', 'max']\n",
        "\n",
        "print(f\"\\nRolling Feature Structure:\")\n",
        "print(f\"Windows: {windows}\")\n",
        "print(f\"Statistics: {stats}\")\n",
        "print(f\"Total combinations per target: {len(windows)} windows √ó {len(stats)} stats = {len(windows) * len(stats)} features\")\n",
        "\n",
        "# Show sample features\n",
        "print(f\"\\nSample PM2.5 Rolling Features:\")\n",
        "for i, feature in enumerate(pm25_rolling[:8]):\n",
        "    print(f\"  {i+1:2d}. {feature}\")\n",
        "    \n",
        "print(f\"\\nSample PM10 Rolling Features:\")\n",
        "for i, feature in enumerate(pm10_rolling[:8]):\n",
        "    print(f\"  {i+1:2d}. {feature}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 9.2 Rolling Features vs Current PM Correlation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 9.2 Rolling Features vs Current PM Correlation\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"ROLLING FEATURES vs CURRENT PM CORRELATION\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# PM2.5 Rolling Features Analysis\n",
        "print(f\"\\nPM2.5 ROLLING FEATURES CORRELATION WITH CURRENT PM2.5:\")\n",
        "print(\"-\" * 55)\n",
        "\n",
        "pm25_correlations = {}\n",
        "for stat_type in stats:\n",
        "    stat_features = [col for col in pm25_rolling if stat_type in col]\n",
        "    if stat_features:\n",
        "        print(f\"\\n{stat_type.upper()} features:\")\n",
        "        correlations = df[['pm2_5'] + stat_features].corr()['pm2_5'].drop('pm2_5')\n",
        "        pm25_correlations[stat_type] = correlations\n",
        "        for feature, corr in correlations.sort_values(ascending=False).items():\n",
        "            window = feature.split('_')[-1]\n",
        "            print(f\"    {window:<4} window: {corr:.3f}\")\n",
        "\n",
        "# PM10 Rolling Features Analysis  \n",
        "print(f\"\\nPM10 ROLLING FEATURES CORRELATION WITH CURRENT PM10:\")\n",
        "print(\"-\" * 54)\n",
        "\n",
        "pm10_correlations = {}\n",
        "for stat_type in stats:\n",
        "    stat_features = [col for col in pm10_rolling if stat_type in col]\n",
        "    if stat_features:\n",
        "        print(f\"\\n{stat_type.upper()} features:\")\n",
        "        correlations = df[['pm10'] + stat_features].corr()['pm10'].drop('pm10')\n",
        "        pm10_correlations[stat_type] = correlations\n",
        "        for feature, corr in correlations.sort_values(ascending=False).items():\n",
        "            window = feature.split('_')[-1]\n",
        "            print(f\"    {window:<4} window: {corr:.3f}\")\n",
        "\n",
        "# Summary insights\n",
        "print(f\"\\nüìä KEY INSIGHTS:\")\n",
        "print(f\"‚Ä¢ Rolling features show how current PM relates to recent historical patterns\")\n",
        "print(f\"‚Ä¢ Higher correlations = better predictive value for current conditions\")\n",
        "print(f\"‚Ä¢ Different statistics capture different aspects of PM behavior\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 9.3 Rolling Features vs Future PM Correlation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 9.3 Rolling Features vs Future PM Correlation\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"ROLLING FEATURES vs FUTURE PM CORRELATION\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Create future PM values for correlation analysis\n",
        "future_horizons = [1, 6, 12, 24, 48, 72]\n",
        "future_pm_data = {}\n",
        "\n",
        "for horizon in future_horizons:\n",
        "    future_pm_data[f'pm2_5_future_{horizon}h'] = df['pm2_5'].shift(-horizon)\n",
        "    future_pm_data[f'pm10_future_{horizon}h'] = df['pm10'].shift(-horizon)\n",
        "\n",
        "future_df = pd.DataFrame(future_pm_data)\n",
        "combined_df = pd.concat([df[all_rolling + ['pm2_5', 'pm10']], future_df], axis=1)\n",
        "\n",
        "# Analyze PM2.5 rolling features vs future PM2.5\n",
        "print(f\"\\nPM2.5 ROLLING FEATURES vs FUTURE PM2.5:\")\n",
        "print(\"-\" * 45)\n",
        "\n",
        "for horizon in future_horizons:\n",
        "    future_col = f'pm2_5_future_{horizon}h'\n",
        "    print(f\"\\n{horizon}h ahead predictions:\")\n",
        "    \n",
        "    # Best rolling feature for this horizon\n",
        "    rolling_corrs = combined_df[pm25_rolling + [future_col]].corr()[future_col].drop(future_col)\n",
        "    best_rolling = rolling_corrs.abs().idxmax()\n",
        "    best_corr = rolling_corrs[best_rolling]\n",
        "    \n",
        "    print(f\"  Best rolling feature: {best_rolling} (corr: {best_corr:.3f})\")\n",
        "    \n",
        "    # Top 3 by statistic type\n",
        "    for stat_type in stats:\n",
        "        stat_features = [col for col in pm25_rolling if stat_type in col]\n",
        "        if stat_features:\n",
        "            stat_corrs = rolling_corrs[stat_features]\n",
        "            if len(stat_corrs) > 0:\n",
        "                best_stat_feature = stat_corrs.abs().idxmax()\n",
        "                best_stat_corr = stat_corrs[best_stat_feature]\n",
        "                window = best_stat_feature.split('_')[-1]\n",
        "                print(f\"    {stat_type:<4}: {window} window ({best_stat_corr:.3f})\")\n",
        "\n",
        "# Analyze PM10 rolling features vs future PM10\n",
        "print(f\"\\nPM10 ROLLING FEATURES vs FUTURE PM10:\")\n",
        "print(\"-\" * 44)\n",
        "\n",
        "for horizon in future_horizons:\n",
        "    future_col = f'pm10_future_{horizon}h'\n",
        "    print(f\"\\n{horizon}h ahead predictions:\")\n",
        "    \n",
        "    # Best rolling feature for this horizon\n",
        "    rolling_corrs = combined_df[pm10_rolling + [future_col]].corr()[future_col].drop(future_col)\n",
        "    best_rolling = rolling_corrs.abs().idxmax()\n",
        "    best_corr = rolling_corrs[best_rolling]\n",
        "    \n",
        "    print(f\"  Best rolling feature: {best_rolling} (corr: {best_corr:.3f})\")\n",
        "    \n",
        "    # Top by statistic type\n",
        "    for stat_type in stats:\n",
        "        stat_features = [col for col in pm10_rolling if stat_type in col]\n",
        "        if stat_features:\n",
        "            stat_corrs = rolling_corrs[stat_features]\n",
        "            if len(stat_corrs) > 0:\n",
        "                best_stat_feature = stat_corrs.abs().idxmax()\n",
        "                best_stat_corr = stat_corrs[best_stat_feature]\n",
        "                window = best_stat_feature.split('_')[-1]\n",
        "                print(f\"    {stat_type:<4}: {window} window ({best_stat_corr:.3f})\")\n",
        "\n",
        "print(f\"\\nüéØ FORECASTING INSIGHTS:\")\n",
        "print(f\"‚Ä¢ Rolling features show predictive power for future PM values\")\n",
        "print(f\"‚Ä¢ Different rolling windows optimal for different prediction horizons\")\n",
        "print(f\"‚Ä¢ Short windows better for short-term, long windows for long-term predictions\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Missing Pollutants Analysis\n",
        "\n",
        "**Focus**: Analyzing NO (Nitric Oxide) and NH3 (Ammonia) - pollutants we haven't analyzed yet.\n",
        "\n",
        "### 10.1 NO and NH3 Overview\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 10.1 NO and NH3 Overview\n",
        "print(\"=\" * 60)\n",
        "print(\"MISSING POLLUTANTS ANALYSIS: NO & NH3\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Check if these pollutants exist in our data\n",
        "missing_pollutants = ['no', 'nh3']\n",
        "available_pollutants = [col for col in missing_pollutants if col in df.columns]\n",
        "missing_from_data = [col for col in missing_pollutants if col not in df.columns]\n",
        "\n",
        "print(f\"Available missing pollutants: {available_pollutants}\")\n",
        "print(f\"Not in dataset: {missing_from_data}\")\n",
        "\n",
        "if available_pollutants:\n",
        "    print(f\"\\nBASIC STATISTICS:\")\n",
        "    for pollutant in available_pollutants:\n",
        "        data = df[pollutant]\n",
        "        print(f\"\\n{pollutant.upper()} (Nitric Oxide):\" if pollutant == 'no' else f\"\\n{pollutant.upper()} (Ammonia):\")\n",
        "        print(f\"  Range: {data.min():.2f} - {data.max():.2f}\")\n",
        "        print(f\"  Mean: {data.mean():.2f}\")\n",
        "        print(f\"  Std: {data.std():.2f}\")\n",
        "        print(f\"  Missing: {data.isnull().sum()} ({(data.isnull().sum()/len(data)*100):.1f}%)\")\n",
        "        \n",
        "        # Check for zeros\n",
        "        zero_count = (data == 0).sum()\n",
        "        if zero_count > 0:\n",
        "            print(f\"  Zero values: {zero_count} ({(zero_count/len(data)*100):.1f}%)\")\n",
        "\n",
        "# Visualize missing pollutants over time\n",
        "if available_pollutants:\n",
        "    fig, axes = plt.subplots(len(available_pollutants), 1, figsize=(15, 4*len(available_pollutants)))\n",
        "    if len(available_pollutants) == 1:\n",
        "        axes = [axes]\n",
        "    \n",
        "    for i, pollutant in enumerate(available_pollutants):\n",
        "        axes[i].plot(df['time'], df[pollutant], alpha=0.7, color='green' if pollutant == 'no' else 'purple')\n",
        "        axes[i].set_title(f'{pollutant.upper()} Concentration Over Time')\n",
        "        axes[i].set_ylabel(f'{pollutant.upper()} (¬µg/m¬≥)')\n",
        "        axes[i].grid(True, alpha=0.3)\n",
        "        \n",
        "    plt.xlabel('Date')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No missing pollutants found in dataset\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 10.2 NO and NH3 Correlation with PM2.5/PM10\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 10.2 NO and NH3 Correlation with PM2.5/PM10\n",
        "if available_pollutants:\n",
        "    print(f\"\\nCORRELATION WITH ML TARGETS:\")\n",
        "    print(\"-\" * 40)\n",
        "    \n",
        "    targets = ['pm2_5', 'pm10']\n",
        "    for target in targets:\n",
        "        print(f\"\\n{target.upper()} correlations:\")\n",
        "        target_data = df[target]\n",
        "        \n",
        "        for pollutant in available_pollutants:\n",
        "            pollutant_data = df[pollutant]\n",
        "            corr = target_data.corr(pollutant_data)\n",
        "            significance = \"\"\n",
        "            if abs(corr) > 0.5:\n",
        "                significance = \" (STRONG)\"\n",
        "            elif abs(corr) > 0.3:\n",
        "                significance = \" (MODERATE)\"\n",
        "            elif abs(corr) > 0.1:\n",
        "                significance = \" (WEAK)\"\n",
        "            else:\n",
        "                significance = \" (NEGLIGIBLE)\"\n",
        "                \n",
        "            print(f\"  {pollutant.upper():<4}: {corr:>6.3f}{significance}\")\n",
        "    \n",
        "    # Compare with other pollutants we analyzed\n",
        "    print(f\"\\nCOMPARISON WITH ANALYZED POLLUTANTS:\")\n",
        "    print(\"-\" * 45)\n",
        "    \n",
        "    analyzed_pollutants = ['carbon_monoxide', 'nitrogen_dioxide', 'ozone', 'sulphur_dioxide']\n",
        "    available_analyzed = [col for col in analyzed_pollutants if col in df.columns]\n",
        "    \n",
        "    all_pollutants = available_pollutants + available_analyzed\n",
        "    \n",
        "    if len(all_pollutants) >= 2:\n",
        "        # Create correlation matrix\n",
        "        corr_matrix = df[all_pollutants + targets].corr()\n",
        "        \n",
        "        # Extract correlations with targets\n",
        "        for target in targets:\n",
        "            print(f\"\\n{target.upper()} correlation ranking:\")\n",
        "            target_corrs = corr_matrix[target].drop(target).abs().sort_values(ascending=False)\n",
        "            for i, (pollutant, corr) in enumerate(target_corrs.items(), 1):\n",
        "                status = \"‚òÖ NEW\" if pollutant in available_pollutants else \"  OLD\"\n",
        "                print(f\"  {i:2d}. {status} {pollutant:<20}: {corr:.3f}\")\n",
        "    \n",
        "    print(f\"\\nüî¨ MISSING POLLUTANTS INSIGHTS:\")\n",
        "    print(f\"‚Ä¢ NO and NH3 provide additional chemical information\")\n",
        "    print(f\"‚Ä¢ Agricultural emissions (NH3) and combustion processes (NO)\")\n",
        "    print(f\"‚Ä¢ May capture different pollution sources than analyzed pollutants\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Cannot analyze correlations - pollutants not in dataset\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Wind Direction Analysis\n",
        "\n",
        "**Focus**: Analyzing wind direction patterns and their relationship with PM concentrations to understand pollution dispersion.\n",
        "\n",
        "### 11.1 Wind Direction Patterns\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 11.1 Wind Direction Patterns\n",
        "print(\"=\" * 60)\n",
        "print(\"WIND DIRECTION ANALYSIS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "if 'wind_direction' in df.columns:\n",
        "    wind_dir = df['wind_direction']\n",
        "    \n",
        "    print(f\"WIND DIRECTION STATISTICS:\")\n",
        "    print(f\"  Range: {wind_dir.min():.1f}¬∞ - {wind_dir.max():.1f}¬∞\")\n",
        "    print(f\"  Mean: {wind_dir.mean():.1f}¬∞\")\n",
        "    print(f\"  Std: {wind_dir.std():.1f}¬∞\")\n",
        "    print(f\"  Missing: {wind_dir.isnull().sum()} ({(wind_dir.isnull().sum()/len(wind_dir)*100):.1f}%)\")\n",
        "    \n",
        "    # Convert degrees to cardinal directions for better understanding\n",
        "    def degrees_to_cardinal(degrees):\n",
        "        \"\"\"Convert wind direction degrees to cardinal directions\"\"\"\n",
        "        if pd.isna(degrees):\n",
        "            return 'Unknown'\n",
        "        \n",
        "        directions = ['N', 'NNE', 'NE', 'ENE', 'E', 'ESE', 'SE', 'SSE',\n",
        "                     'S', 'SSW', 'SW', 'WSW', 'W', 'WNW', 'NW', 'NNW']\n",
        "        \n",
        "        # Each direction covers 22.5 degrees (360/16)\n",
        "        index = int((degrees + 11.25) / 22.5) % 16\n",
        "        return directions[index]\n",
        "    \n",
        "    # Add cardinal directions\n",
        "    df['wind_cardinal'] = wind_dir.apply(degrees_to_cardinal)\n",
        "    \n",
        "    # Analyze wind direction distribution\n",
        "    print(f\"\\nWIND DIRECTION DISTRIBUTION:\")\n",
        "    direction_counts = df['wind_cardinal'].value_counts()\n",
        "    print(direction_counts)\n",
        "    \n",
        "    # Visualize wind direction distribution\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "    \n",
        "    # Wind rose plot (polar)\n",
        "    theta = np.radians(wind_dir.dropna())\n",
        "    ax1 = plt.subplot(121, projection='polar')\n",
        "    ax1.hist(theta, bins=16, alpha=0.7, color='skyblue')\n",
        "    ax1.set_title('Wind Direction Distribution (Wind Rose)')\n",
        "    ax1.set_theta_zero_location('N')\n",
        "    ax1.set_theta_direction(-1)\n",
        "    \n",
        "    # Cardinal direction bar plot\n",
        "    ax2 = plt.subplot(122)\n",
        "    direction_counts.plot(kind='bar', ax=ax2, color='lightcoral')\n",
        "    ax2.set_title('Wind Direction by Cardinal Points')\n",
        "    ax2.set_xlabel('Direction')\n",
        "    ax2.set_ylabel('Frequency')\n",
        "    ax2.tick_params(axis='x', rotation=45)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Wind direction data not available in dataset\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 11.2 Wind Direction vs PM Correlation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 11.2 Wind Direction vs PM Correlation\n",
        "if 'wind_direction' in df.columns and 'wind_cardinal' in df.columns:\n",
        "    print(f\"\\nWIND DIRECTION vs PM CONCENTRATIONS:\")\n",
        "    print(\"-\" * 45)\n",
        "    \n",
        "    # Analyze PM levels by wind direction\n",
        "    targets = ['pm2_5', 'pm10']\n",
        "    \n",
        "    for target in targets:\n",
        "        print(f\"\\n{target.upper()} by Wind Direction:\")\n",
        "        pm_by_direction = df.groupby('wind_cardinal')[target].agg(['mean', 'std', 'count']).round(2)\n",
        "        pm_by_direction = pm_by_direction.sort_values('mean', ascending=False)\n",
        "        \n",
        "        print(pm_by_direction)\n",
        "        \n",
        "        # Find pollution source directions\n",
        "        max_direction = pm_by_direction['mean'].idxmax()\n",
        "        min_direction = pm_by_direction['mean'].idxmin()\n",
        "        \n",
        "        print(f\"\\n  üî• Highest {target.upper()}: {max_direction} direction ({pm_by_direction.loc[max_direction, 'mean']:.1f} ¬µg/m¬≥)\")\n",
        "        print(f\"  üåø Lowest {target.upper()}: {min_direction} direction ({pm_by_direction.loc[min_direction, 'mean']:.1f} ¬µg/m¬≥)\")\n",
        "        \n",
        "        # Visualize PM by wind direction\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        \n",
        "        plt.subplot(1, 2, 1)\n",
        "        pm_by_direction['mean'].plot(kind='bar', color='orange' if target == 'pm2_5' else 'red')\n",
        "        plt.title(f'{target.upper()} Mean Concentration by Wind Direction')\n",
        "        plt.xlabel('Wind Direction')\n",
        "        plt.ylabel(f'{target.upper()} (¬µg/m¬≥)')\n",
        "        plt.xticks(rotation=45)\n",
        "        \n",
        "        # Polar plot showing PM levels by direction\n",
        "        plt.subplot(1, 2, 2, projection='polar')\n",
        "        \n",
        "        # Convert cardinal directions back to angles\n",
        "        direction_angles = {\n",
        "            'N': 0, 'NNE': 22.5, 'NE': 45, 'ENE': 67.5,\n",
        "            'E': 90, 'ESE': 112.5, 'SE': 135, 'SSE': 157.5,\n",
        "            'S': 180, 'SSW': 202.5, 'SW': 225, 'WSW': 247.5,\n",
        "            'W': 270, 'WNW': 292.5, 'NW': 315, 'NNW': 337.5\n",
        "        }\n",
        "        \n",
        "        angles = [np.radians(direction_angles.get(direction, 0)) for direction in pm_by_direction.index]\n",
        "        values = pm_by_direction['mean'].values\n",
        "        \n",
        "        plt.polar(angles, values, 'o-', color='red' if target == 'pm10' else 'orange')\n",
        "        plt.fill(angles, values, alpha=0.3, color='red' if target == 'pm10' else 'orange')\n",
        "        plt.title(f'{target.upper()} by Wind Direction (Polar)')\n",
        "        plt.thetagrids(range(0, 360, 45), ['N', 'NE', 'E', 'SE', 'S', 'SW', 'W', 'NW'])\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "    \n",
        "    print(f\"\\nüå¨Ô∏è WIND DIRECTION INSIGHTS:\")\n",
        "    print(f\"‚Ä¢ Wind direction reveals potential pollution source locations\")\n",
        "    print(f\"‚Ä¢ Higher PM from certain directions = pollution sources upwind\")\n",
        "    print(f\"‚Ä¢ Lower PM from certain directions = cleaner air sources\")\n",
        "    print(f\"‚Ä¢ Important for source apportionment and prediction modeling\")\n",
        "    \n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Cannot analyze wind direction - data not available\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12. Interaction Features Analysis\n",
        "\n",
        "**Focus**: Analyzing 5 interaction features to determine if combined variables provide better predictive power than individual features.\n",
        "\n",
        "### 12.1 Interaction Features Overview\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 12.1 Interaction Features Overview\n",
        "print(\"=\" * 60)\n",
        "print(\"INTERACTION FEATURES ANALYSIS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Identify interaction features\n",
        "interaction_features = [col for col in df.columns if 'interaction' in col]\n",
        "print(f\"Total Interaction Features: {len(interaction_features)}\")\n",
        "\n",
        "if interaction_features:\n",
        "    print(f\"\\nInteraction Features:\")\n",
        "    for i, feature in enumerate(interaction_features, 1):\n",
        "        # Parse the feature name to understand what it combines\n",
        "        parts = feature.replace('_interaction', '').split('_')\n",
        "        if len(parts) >= 2:\n",
        "            var1 = '_'.join(parts[:-1])\n",
        "            var2 = parts[-1]\n",
        "            print(f\"  {i}. {feature:<30} = {var1} √ó {var2}\")\n",
        "        else:\n",
        "            print(f\"  {i}. {feature}\")\n",
        "    \n",
        "    # Basic statistics for interaction features\n",
        "    print(f\"\\nINTERACTION FEATURES STATISTICS:\")\n",
        "    interaction_stats = df[interaction_features].describe()\n",
        "    print(interaction_stats.round(2))\n",
        "    \n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No interaction features found in dataset\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 12.2 Interaction Features vs Individual Features Comparison\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 12.2 Interaction Features vs Individual Features Comparison\n",
        "if interaction_features:\n",
        "    print(f\"\\nINTERACTION vs INDIVIDUAL FEATURES CORRELATION:\")\n",
        "    print(\"-\" * 55)\n",
        "    \n",
        "    targets = ['pm2_5', 'pm10']\n",
        "    \n",
        "    # Analysis for each interaction feature\n",
        "    interaction_analysis = {}\n",
        "    \n",
        "    for interaction in interaction_features:\n",
        "        print(f\"\\n{interaction.upper()}:\")\n",
        "        \n",
        "        # Parse individual components\n",
        "        if 'temp_humidity' in interaction:\n",
        "            components = ['temperature', 'humidity']\n",
        "        elif 'temp_wind' in interaction:\n",
        "            components = ['temperature', 'wind_speed']\n",
        "        elif 'pm2_5_temp' in interaction:\n",
        "            components = ['pm2_5', 'temperature']\n",
        "        elif 'pm2_5_humidity' in interaction:\n",
        "            components = ['pm2_5', 'humidity']\n",
        "        elif 'wind_pm2_5' in interaction:\n",
        "            components = ['wind_speed', 'pm2_5']\n",
        "        else:\n",
        "            components = []\n",
        "        \n",
        "        # Calculate correlations with targets\n",
        "        interaction_analysis[interaction] = {'components': components}\n",
        "        \n",
        "        for target in targets:\n",
        "            if target in df.columns and interaction in df.columns:\n",
        "                interaction_corr = df[target].corr(df[interaction])\n",
        "                \n",
        "                # Compare with individual component correlations\n",
        "                component_corrs = []\n",
        "                for comp in components:\n",
        "                    if comp in df.columns:\n",
        "                        comp_corr = df[target].corr(df[comp])\n",
        "                        component_corrs.append((comp, comp_corr))\n",
        "                \n",
        "                # Store results\n",
        "                interaction_analysis[interaction][target] = {\n",
        "                    'interaction_corr': interaction_corr,\n",
        "                    'component_corrs': component_corrs\n",
        "                }\n",
        "                \n",
        "                print(f\"  {target.upper()} correlation:\")\n",
        "                print(f\"    Interaction feature: {interaction_corr:>6.3f}\")\n",
        "                for comp, corr in component_corrs:\n",
        "                    print(f\"    {comp:<15}: {corr:>6.3f}\")\n",
        "                \n",
        "                # Determine if interaction adds value\n",
        "                max_individual = max([abs(corr) for _, corr in component_corrs]) if component_corrs else 0\n",
        "                if abs(interaction_corr) > max_individual:\n",
        "                    print(f\"    ‚úÖ Interaction IMPROVES correlation (+{abs(interaction_corr) - max_individual:.3f})\")\n",
        "                else:\n",
        "                    print(f\"    ‚ùå Interaction REDUCES correlation (-{max_individual - abs(interaction_corr):.3f})\")\n",
        "    \n",
        "    # Summary of interaction feature value\n",
        "    print(f\"\\nüîó INTERACTION FEATURES SUMMARY:\")\n",
        "    useful_interactions = 0\n",
        "    total_comparisons = 0\n",
        "    \n",
        "    for interaction, analysis in interaction_analysis.items():\n",
        "        for target in targets:\n",
        "            if target in analysis:\n",
        "                total_comparisons += 1\n",
        "                interaction_corr = abs(analysis[target]['interaction_corr'])\n",
        "                max_individual = max([abs(corr) for _, corr in analysis[target]['component_corrs']]) if analysis[target]['component_corrs'] else 0\n",
        "                \n",
        "                if interaction_corr > max_individual:\n",
        "                    useful_interactions += 1\n",
        "    \n",
        "    if total_comparisons > 0:\n",
        "        improvement_rate = (useful_interactions / total_comparisons) * 100\n",
        "        print(f\"‚Ä¢ {useful_interactions}/{total_comparisons} interactions improve over individual features ({improvement_rate:.1f}%)\")\n",
        "        \n",
        "        if improvement_rate > 50:\n",
        "            print(f\"‚Ä¢ ‚úÖ RECOMMENDATION: Include interaction features in model\")\n",
        "        else:\n",
        "            print(f\"‚Ä¢ ‚ùå RECOMMENDATION: Individual features may be sufficient\")\n",
        "    \n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Cannot analyze interactions - no interaction features found\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 13. Binary Indicators Analysis\n",
        "\n",
        "**Focus**: Analyzing binary indicator features (is_hot, is_rush_hour, etc.) to determine their categorical predictive value.\n",
        "\n",
        "### 13.1 Binary Indicators Overview\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 13.1 Binary Indicators Overview\n",
        "print(\"=\" * 60)\n",
        "print(\"BINARY INDICATORS ANALYSIS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Identify binary indicator features\n",
        "binary_features = [col for col in df.columns if col.startswith('is_')]\n",
        "print(f\"Total Binary Indicator Features: {len(binary_features)}\")\n",
        "\n",
        "if binary_features:\n",
        "    print(f\"\\nBinary Indicator Features:\")\n",
        "    \n",
        "    # Categorize binary features\n",
        "    categories = {\n",
        "        'Weather': [col for col in binary_features if any(x in col for x in ['hot', 'cold', 'humidity', 'wind', 'pressure'])],\n",
        "        'Time': [col for col in binary_features if any(x in col for x in ['spring', 'summer', 'autumn', 'winter', 'night', 'rush'])],\n",
        "        'Pollution': [col for col in binary_features if any(x in col for x in ['pm2_5', 'pm10', 'no2', 'o3', 'co', 'so2'])]\n",
        "    }\n",
        "    \n",
        "    for category, features in categories.items():\n",
        "        if features:\n",
        "            print(f\"\\n{category} Indicators ({len(features)}):\")\n",
        "            for feature in features:\n",
        "                # Calculate distribution\n",
        "                if feature in df.columns:\n",
        "                    true_count = df[feature].sum()\n",
        "                    total_count = len(df)\n",
        "                    true_pct = (true_count / total_count) * 100\n",
        "                    print(f\"  {feature:<25}: {true_count:>4}/{total_count} ({true_pct:>5.1f}%)\")\n",
        "    \n",
        "    # Show overall distribution\n",
        "    print(f\"\\nBINARY FEATURES DISTRIBUTION:\")\n",
        "    binary_stats = df[binary_features].sum().sort_values(ascending=False)\n",
        "    total_records = len(df)\n",
        "    \n",
        "    for feature, count in binary_stats.items():\n",
        "        percentage = (count / total_records) * 100\n",
        "        print(f\"  {feature:<25}: {count:>4} ({percentage:>5.1f}%)\")\n",
        "        \n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No binary indicator features found in dataset\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 14. Comprehensive Feature Ranking\n",
        "\n",
        "**Focus**: Final ranking of ALL features for model selection based on comprehensive analysis.\n",
        "\n",
        "### 14.1 Feature Importance Ranking\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 14.1 Comprehensive Feature Importance Ranking\n",
        "print(\"=\" * 60)\n",
        "print(\"COMPREHENSIVE FEATURE RANKING FOR MODEL SELECTION\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Get all feature categories\n",
        "all_features = [col for col in df.columns if col not in ['time', 'time_str', 'wind_cardinal']]\n",
        "targets = ['pm2_5', 'pm10']\n",
        "\n",
        "feature_rankings = {}\n",
        "\n",
        "print(f\"Analyzing {len(all_features)} features for model selection...\")\n",
        "\n",
        "for target in targets:\n",
        "    print(f\"\\n{target.upper()} FEATURE RANKING:\")\n",
        "    print(\"-\" * 30)\n",
        "    \n",
        "    # Calculate correlations for all features\n",
        "    correlations = {}\n",
        "    \n",
        "    for feature in all_features:\n",
        "        if feature != target and feature in df.columns:\n",
        "            try:\n",
        "                corr = df[target].corr(df[feature])\n",
        "                if not pd.isna(corr):\n",
        "                    correlations[feature] = abs(corr)\n",
        "            except:\n",
        "                continue\n",
        "    \n",
        "    # Sort by correlation strength\n",
        "    sorted_correlations = sorted(correlations.items(), key=lambda x: x[1], reverse=True)\n",
        "    \n",
        "    # Categorize features for better understanding\n",
        "    feature_categories = {\n",
        "        'Raw Pollutants': [f for f in all_features if f in ['carbon_monoxide', 'nitrogen_dioxide', 'ozone', 'sulphur_dioxide', 'no', 'nh3']],\n",
        "        'Weather': [f for f in all_features if f in ['temperature', 'humidity', 'pressure', 'wind_speed', 'wind_direction']],\n",
        "        'Time Features': [f for f in all_features if any(x in f for x in ['hour_', 'day_', 'month_', 'is_spring', 'is_summer', 'is_autumn', 'is_winter'])],\n",
        "        'Lag Features': [f for f in all_features if 'lag_' in f],\n",
        "        'Rolling Features': [f for f in all_features if 'rolling_' in f],\n",
        "        'Change Rate': [f for f in all_features if 'change_rate' in f],\n",
        "        'Derived Features': [f for f in all_features if any(x in f for x in ['squared', 'cubed', 'is_hot', 'is_cold', 'is_high', 'is_low'])],\n",
        "        'Interactions': [f for f in all_features if 'interaction' in f]\n",
        "    }\n",
        "    \n",
        "    # Show top features overall\n",
        "    print(f\"\\nTOP 15 FEATURES by Correlation:\")\n",
        "    for i, (feature, corr) in enumerate(sorted_correlations[:15], 1):\n",
        "        # Identify category\n",
        "        category = \"Other\"\n",
        "        for cat, features in feature_categories.items():\n",
        "            if feature in features:\n",
        "                category = cat\n",
        "                break\n",
        "        \n",
        "        print(f\"  {i:2d}. {feature:<35} {corr:.3f} ({category})\")\n",
        "    \n",
        "    # Show top features by category\n",
        "    print(f\"\\nTOP FEATURES BY CATEGORY:\")\n",
        "    for category, category_features in feature_categories.items():\n",
        "        category_corrs = [(f, correlations.get(f, 0)) for f in category_features if f in correlations]\n",
        "        if category_corrs:\n",
        "            top_feature = max(category_corrs, key=lambda x: x[1])\n",
        "            print(f\"  {category:<18}: {top_feature[0]:<30} ({top_feature[1]:.3f})\")\n",
        "    \n",
        "    # Store rankings\n",
        "    feature_rankings[target] = sorted_correlations\n",
        "\n",
        "# Feature selection recommendations\n",
        "print(f\"\\nüéØ FEATURE SELECTION RECOMMENDATIONS:\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Based on our EDA findings\n",
        "print(f\"\\nHIGH PRIORITY FEATURES (Strong correlations + EDA insights):\")\n",
        "high_priority = []\n",
        "\n",
        "# Add features based on EDA analysis\n",
        "weather_features = ['temperature', 'humidity', 'pressure', 'wind_speed']\n",
        "high_priority.extend([f for f in weather_features if f in all_features])\n",
        "\n",
        "# Key pollutants from Section 3 analysis\n",
        "key_pollutants = ['carbon_monoxide', 'ozone', 'sulphur_dioxide']\n",
        "high_priority.extend([f for f in key_pollutants if f in all_features])\n",
        "\n",
        "# Short-term lags from Section 8.2 analysis\n",
        "short_lags = [f for f in all_features if 'lag_' in f and any(x in f for x in ['1h', '2h', '3h'])]\n",
        "high_priority.extend(short_lags)\n",
        "\n",
        "# Time features\n",
        "time_features = [f for f in all_features if any(x in f for x in ['hour_sin', 'hour_cos', 'day_sin', 'day_cos'])]\n",
        "high_priority.extend(time_features)\n",
        "\n",
        "print(f\"Total high priority features: {len(set(high_priority))}\")\n",
        "for feature in sorted(set(high_priority)):\n",
        "    if feature in df.columns:\n",
        "        pm25_corr = df['pm2_5'].corr(df[feature]) if 'pm2_5' in df.columns else 0\n",
        "        pm10_corr = df['pm10'].corr(df[feature]) if 'pm10' in df.columns else 0\n",
        "        print(f\"  {feature:<30}: PM2.5({pm25_corr:>6.3f}) PM10({pm10_corr:>6.3f})\")\n",
        "\n",
        "print(f\"\\nMEDIUM PRIORITY FEATURES (Based on EDA analysis):\")\n",
        "medium_features = []\n",
        "\n",
        "# Rolling features (keep some based on analysis)\n",
        "rolling_means = [f for f in all_features if 'rolling_mean' in f and any(x in f for x in ['3h', '6h'])]\n",
        "medium_features.extend(rolling_means)\n",
        "\n",
        "# Change rate features\n",
        "change_rates = [f for f in all_features if 'change_rate' in f]\n",
        "medium_features.extend(change_rates)\n",
        "\n",
        "# Binary indicators that showed promise\n",
        "useful_binary = [f for f in all_features if f.startswith('is_') and any(x in f for x in ['rush', 'night'])]\n",
        "medium_features.extend(useful_binary)\n",
        "\n",
        "print(f\"Total medium priority features: {len(set(medium_features))}\")\n",
        "\n",
        "print(f\"\\nLOW PRIORITY FEATURES (Based on EDA analysis):\")\n",
        "print(f\"‚Ä¢ Long-term lags (6h+) - Section 8.2 showed 0% utility\")\n",
        "print(f\"‚Ä¢ Most squared/cubed features - likely redundant with originals\")\n",
        "print(f\"‚Ä¢ Nitrogen dioxide - high correlation with CO (multicollinearity)\")\n",
        "print(f\"‚Ä¢ Most binary indicators - may not add significant value\")\n",
        "\n",
        "print(f\"\\nüìã FINAL FEATURE SELECTION STRATEGY:\")\n",
        "print(f\"1. Start with HIGH PRIORITY features ({len(set(high_priority))} features)\")\n",
        "print(f\"2. Add MEDIUM PRIORITY features if model performance improves\")\n",
        "print(f\"3. Use feature selection algorithms to fine-tune\")\n",
        "print(f\"4. Monitor for multicollinearity and remove redundant features\")\n",
        "print(f\"5. Validate feature importance through model training\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 15. Secondary Pollutants ‚Üí Future PM Analysis\n",
        "\n",
        "**Focus**: CRITICAL MISSING ANALYSIS - How current secondary pollutants (CO, NO2, O3, SO2, NO, NH3) predict future PM2.5/PM10 values.\n",
        "\n",
        "### 15.1 Current Pollutants ‚Üí Future PM Lead-Lag Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "SECONDARY POLLUTANTS ‚Üí FUTURE PM PREDICTION ANALYSIS\n",
            "============================================================\n",
            "Available secondary pollutants: ['carbon_monoxide', 'nitrogen_dioxide', 'ozone', 'sulphur_dioxide', 'no', 'nh3']\n",
            "Missing from dataset: []\n",
            "\n",
            "Analyzing 6 pollutants across 6 prediction horizons...\n",
            "\n",
            "Creating future PM targets for lead-lag analysis...\n",
            "‚úì Created future PM targets for prediction horizons: [1, 6, 12, 24, 48, 72]\n",
            "‚úì Total correlation pairs to analyze: 6 √ó 2 √ó 6 = 72\n"
          ]
        }
      ],
      "source": [
        "# 15.1 Current Pollutants ‚Üí Future PM Lead-Lag Analysis\n",
        "print(\"=\" * 60)\n",
        "print(\"SECONDARY POLLUTANTS ‚Üí FUTURE PM PREDICTION ANALYSIS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Define secondary pollutants to analyze\n",
        "secondary_pollutants = ['carbon_monoxide', 'nitrogen_dioxide', 'ozone', 'sulphur_dioxide', 'no', 'nh3']\n",
        "available_pollutants = [col for col in secondary_pollutants if col in df.columns]\n",
        "missing_pollutants = [col for col in secondary_pollutants if col not in df.columns]\n",
        "\n",
        "print(f\"Available secondary pollutants: {available_pollutants}\")\n",
        "print(f\"Missing from dataset: {missing_pollutants}\")\n",
        "\n",
        "if not available_pollutants:\n",
        "    print(\"‚ö†Ô∏è No secondary pollutants available for analysis\")\n",
        "else:\n",
        "    # Define prediction horizons (same as Section 8.3 weather analysis)\n",
        "    prediction_horizons = [1, 6, 12, 24, 48, 72]\n",
        "    targets = ['pm2_5', 'pm10']\n",
        "    \n",
        "    print(f\"\\nAnalyzing {len(available_pollutants)} pollutants across {len(prediction_horizons)} prediction horizons...\")\n",
        "    \n",
        "    # Create future PM values for correlation analysis\n",
        "    print(f\"\\nCreating future PM targets for lead-lag analysis...\")\n",
        "    future_pm_data = {}\n",
        "    \n",
        "    for horizon in prediction_horizons:\n",
        "        for target in targets:\n",
        "            future_col = f'{target}_future_{horizon}h'\n",
        "            future_pm_data[future_col] = df[target].shift(-horizon)\n",
        "    \n",
        "    # Combine current pollutants with future PM data\n",
        "    pollutant_future_df = pd.concat([df[available_pollutants], pd.DataFrame(future_pm_data)], axis=1)\n",
        "    \n",
        "    print(f\"‚úì Created future PM targets for prediction horizons: {prediction_horizons}\")\n",
        "    print(f\"‚úì Total correlation pairs to analyze: {len(available_pollutants)} √ó {len(targets)} √ó {len(prediction_horizons)} = {len(available_pollutants) * len(targets) * len(prediction_horizons)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 15.2 Pollutant Lead-Lag Correlation Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "POLLUTANT ‚Üí FUTURE PM CORRELATION MATRIX\n",
            "============================================================\n",
            "\n",
            "CARBON_MONOXIDE ‚Üí FUTURE PM PREDICTION POWER:\n",
            "-------------------------------------------------------\n",
            "\n",
            "CARBON_MONOXIDE ‚Üí PM2_5:\n",
            "Horizon    Correlation  Predictive Power   Assessment\n",
            "--------------------------------------------------\n",
            "1h            0.496       0.496          üü° MODERATE predictor\n",
            "6h            0.426       0.426          üü° MODERATE predictor\n",
            "12h           0.404       0.404          üü° MODERATE predictor\n",
            "1d            0.418       0.418          üü° MODERATE predictor\n",
            "2d            0.312       0.312          üü° MODERATE predictor\n",
            "3d            0.158       0.158          ‚ö™ MINIMAL predictor\n",
            "\n",
            "  üìä SUMMARY for CARBON_MONOXIDE ‚Üí PM2_5:\n",
            "    Best prediction horizon: 1h (corr: 0.496)\n",
            "    Max correlation: 0.496\n",
            "    Average correlation: 0.369\n",
            "    ‚úÖ EXCELLENT early warning indicator (<6h, strong correlation)\n",
            "\n",
            "CARBON_MONOXIDE ‚Üí PM10:\n",
            "Horizon    Correlation  Predictive Power   Assessment\n",
            "--------------------------------------------------\n",
            "1h           -0.176       0.176          ‚ö™ MINIMAL predictor\n",
            "6h           -0.141       0.141          ‚ö™ MINIMAL predictor\n",
            "12h          -0.141       0.141          ‚ö™ MINIMAL predictor\n",
            "1d           -0.112       0.112          ‚ö™ MINIMAL predictor\n",
            "2d           -0.024       0.024          ‚ùå NEGLIGIBLE predictor\n",
            "3d           -0.043       0.043          ‚ùå NEGLIGIBLE predictor\n",
            "\n",
            "  üìä SUMMARY for CARBON_MONOXIDE ‚Üí PM10:\n",
            "    Best prediction horizon: 1h (corr: -0.176)\n",
            "    Max correlation: 0.176\n",
            "    Average correlation: 0.106\n",
            "    üü¢ FAIR early warning indicator (<24h, weak correlation)\n",
            "\n",
            "NITROGEN_DIOXIDE ‚Üí FUTURE PM PREDICTION POWER:\n",
            "-------------------------------------------------------\n",
            "\n",
            "NITROGEN_DIOXIDE ‚Üí PM2_5:\n",
            "Horizon    Correlation  Predictive Power   Assessment\n",
            "--------------------------------------------------\n",
            "1h            0.275       0.275          üü¢ WEAK predictor\n",
            "6h            0.245       0.245          üü¢ WEAK predictor\n",
            "12h           0.235       0.235          üü¢ WEAK predictor\n",
            "1d            0.272       0.272          üü¢ WEAK predictor\n",
            "2d            0.222       0.222          üü¢ WEAK predictor\n",
            "3d            0.124       0.124          ‚ö™ MINIMAL predictor\n",
            "\n",
            "  üìä SUMMARY for NITROGEN_DIOXIDE ‚Üí PM2_5:\n",
            "    Best prediction horizon: 1h (corr: 0.275)\n",
            "    Max correlation: 0.275\n",
            "    Average correlation: 0.229\n",
            "    üü° GOOD early warning indicator (<12h, moderate correlation)\n",
            "\n",
            "NITROGEN_DIOXIDE ‚Üí PM10:\n",
            "Horizon    Correlation  Predictive Power   Assessment\n",
            "--------------------------------------------------\n",
            "1h            0.005       0.005          ‚ùå NEGLIGIBLE predictor\n",
            "6h            0.085       0.085          ‚ùå NEGLIGIBLE predictor\n",
            "12h           0.007       0.007          ‚ùå NEGLIGIBLE predictor\n",
            "1d           -0.052       0.052          ‚ùå NEGLIGIBLE predictor\n",
            "2d           -0.098       0.098          ‚ùå NEGLIGIBLE predictor\n",
            "3d           -0.149       0.149          ‚ö™ MINIMAL predictor\n",
            "\n",
            "  üìä SUMMARY for NITROGEN_DIOXIDE ‚Üí PM10:\n",
            "    Best prediction horizon: 72h (corr: -0.149)\n",
            "    Max correlation: 0.149\n",
            "    Average correlation: 0.066\n",
            "    ‚ùå LIMITED early warning value\n",
            "\n",
            "OZONE ‚Üí FUTURE PM PREDICTION POWER:\n",
            "-------------------------------------------------------\n",
            "\n",
            "OZONE ‚Üí PM2_5:\n",
            "Horizon    Correlation  Predictive Power   Assessment\n",
            "--------------------------------------------------\n",
            "1h            0.405       0.405          üü° MODERATE predictor\n",
            "6h            0.393       0.393          üü° MODERATE predictor\n",
            "12h           0.430       0.430          üü° MODERATE predictor\n",
            "1d            0.229       0.229          üü¢ WEAK predictor\n",
            "2d            0.163       0.163          ‚ö™ MINIMAL predictor\n",
            "3d            0.095       0.095          ‚ùå NEGLIGIBLE predictor\n",
            "\n",
            "  üìä SUMMARY for OZONE ‚Üí PM2_5:\n",
            "    Best prediction horizon: 12h (corr: 0.430)\n",
            "    Max correlation: 0.430\n",
            "    Average correlation: 0.286\n",
            "    üü° GOOD early warning indicator (<12h, moderate correlation)\n",
            "\n",
            "OZONE ‚Üí PM10:\n",
            "Horizon    Correlation  Predictive Power   Assessment\n",
            "--------------------------------------------------\n",
            "1h           -0.093       0.093          ‚ùå NEGLIGIBLE predictor\n",
            "6h           -0.060       0.060          ‚ùå NEGLIGIBLE predictor\n",
            "12h           0.191       0.191          ‚ö™ MINIMAL predictor\n",
            "1d           -0.048       0.048          ‚ùå NEGLIGIBLE predictor\n",
            "2d            0.036       0.036          ‚ùå NEGLIGIBLE predictor\n",
            "3d            0.092       0.092          ‚ùå NEGLIGIBLE predictor\n",
            "\n",
            "  üìä SUMMARY for OZONE ‚Üí PM10:\n",
            "    Best prediction horizon: 12h (corr: 0.191)\n",
            "    Max correlation: 0.191\n",
            "    Average correlation: 0.087\n",
            "    üü¢ FAIR early warning indicator (<24h, weak correlation)\n",
            "\n",
            "SULPHUR_DIOXIDE ‚Üí FUTURE PM PREDICTION POWER:\n",
            "-------------------------------------------------------\n",
            "\n",
            "SULPHUR_DIOXIDE ‚Üí PM2_5:\n",
            "Horizon    Correlation  Predictive Power   Assessment\n",
            "--------------------------------------------------\n",
            "1h            0.380       0.380          üü° MODERATE predictor\n",
            "6h            0.265       0.265          üü¢ WEAK predictor\n",
            "12h           0.174       0.174          ‚ö™ MINIMAL predictor\n",
            "1d            0.174       0.174          ‚ö™ MINIMAL predictor\n",
            "2d            0.245       0.245          üü¢ WEAK predictor\n",
            "3d            0.170       0.170          ‚ö™ MINIMAL predictor\n",
            "\n",
            "  üìä SUMMARY for SULPHUR_DIOXIDE ‚Üí PM2_5:\n",
            "    Best prediction horizon: 1h (corr: 0.380)\n",
            "    Max correlation: 0.380\n",
            "    Average correlation: 0.235\n",
            "    ‚úÖ EXCELLENT early warning indicator (<6h, strong correlation)\n",
            "\n",
            "SULPHUR_DIOXIDE ‚Üí PM10:\n",
            "Horizon    Correlation  Predictive Power   Assessment\n",
            "--------------------------------------------------\n",
            "1h            0.279       0.279          üü¢ WEAK predictor\n",
            "6h           -0.006       0.006          ‚ùå NEGLIGIBLE predictor\n",
            "12h          -0.084       0.084          ‚ùå NEGLIGIBLE predictor\n",
            "1d            0.192       0.192          ‚ö™ MINIMAL predictor\n",
            "2d            0.283       0.283          üü¢ WEAK predictor\n",
            "3d            0.204       0.204          üü¢ WEAK predictor\n",
            "\n",
            "  üìä SUMMARY for SULPHUR_DIOXIDE ‚Üí PM10:\n",
            "    Best prediction horizon: 48h (corr: 0.283)\n",
            "    Max correlation: 0.283\n",
            "    Average correlation: 0.175\n",
            "    ‚ùå LIMITED early warning value\n",
            "\n",
            "NO ‚Üí FUTURE PM PREDICTION POWER:\n",
            "-------------------------------------------------------\n",
            "\n",
            "NO ‚Üí PM2_5:\n",
            "Horizon    Correlation  Predictive Power   Assessment\n",
            "--------------------------------------------------\n",
            "1h            0.139       0.139          ‚ö™ MINIMAL predictor\n",
            "6h           -0.039       0.039          ‚ùå NEGLIGIBLE predictor\n",
            "12h           0.060       0.060          ‚ùå NEGLIGIBLE predictor\n",
            "1d            0.213       0.213          üü¢ WEAK predictor\n",
            "2d            0.174       0.174          ‚ö™ MINIMAL predictor\n",
            "3d            0.202       0.202          üü¢ WEAK predictor\n",
            "\n",
            "  üìä SUMMARY for NO ‚Üí PM2_5:\n",
            "    Best prediction horizon: 24h (corr: 0.213)\n",
            "    Max correlation: 0.213\n",
            "    Average correlation: 0.138\n",
            "    üü¢ FAIR early warning indicator (<24h, weak correlation)\n",
            "\n",
            "NO ‚Üí PM10:\n",
            "Horizon    Correlation  Predictive Power   Assessment\n",
            "--------------------------------------------------\n",
            "1h            0.184       0.184          ‚ö™ MINIMAL predictor\n",
            "6h           -0.211       0.211          üü¢ WEAK predictor\n",
            "12h          -0.098       0.098          ‚ùå NEGLIGIBLE predictor\n",
            "1d            0.207       0.207          üü¢ WEAK predictor\n",
            "2d            0.189       0.189          ‚ö™ MINIMAL predictor\n",
            "3d            0.155       0.155          ‚ö™ MINIMAL predictor\n",
            "\n",
            "  üìä SUMMARY for NO ‚Üí PM10:\n",
            "    Best prediction horizon: 6h (corr: -0.211)\n",
            "    Max correlation: 0.211\n",
            "    Average correlation: 0.174\n",
            "    üü° GOOD early warning indicator (<12h, moderate correlation)\n",
            "\n",
            "NH3 ‚Üí FUTURE PM PREDICTION POWER:\n",
            "-------------------------------------------------------\n",
            "\n",
            "NH3 ‚Üí PM2_5:\n",
            "Horizon    Correlation  Predictive Power   Assessment\n",
            "--------------------------------------------------\n",
            "1h            0.388       0.388          üü° MODERATE predictor\n",
            "6h            0.376       0.376          üü° MODERATE predictor\n",
            "12h           0.341       0.341          üü° MODERATE predictor\n",
            "1d            0.328       0.328          üü° MODERATE predictor\n",
            "2d            0.203       0.203          üü¢ WEAK predictor\n",
            "3d            0.107       0.107          ‚ö™ MINIMAL predictor\n",
            "\n",
            "  üìä SUMMARY for NH3 ‚Üí PM2_5:\n",
            "    Best prediction horizon: 1h (corr: 0.388)\n",
            "    Max correlation: 0.388\n",
            "    Average correlation: 0.291\n",
            "    ‚úÖ EXCELLENT early warning indicator (<6h, strong correlation)\n",
            "\n",
            "NH3 ‚Üí PM10:\n",
            "Horizon    Correlation  Predictive Power   Assessment\n",
            "--------------------------------------------------\n",
            "1h            0.191       0.191          ‚ö™ MINIMAL predictor\n",
            "6h            0.274       0.274          üü¢ WEAK predictor\n",
            "12h           0.128       0.128          ‚ö™ MINIMAL predictor\n",
            "1d            0.124       0.124          ‚ö™ MINIMAL predictor\n",
            "2d            0.081       0.081          ‚ùå NEGLIGIBLE predictor\n",
            "3d            0.113       0.113          ‚ö™ MINIMAL predictor\n",
            "\n",
            "  üìä SUMMARY for NH3 ‚Üí PM10:\n",
            "    Best prediction horizon: 6h (corr: 0.274)\n",
            "    Max correlation: 0.274\n",
            "    Average correlation: 0.152\n",
            "    üü° GOOD early warning indicator (<12h, moderate correlation)\n",
            "\n",
            "üéØ POLLUTANT PREDICTIVE POWER SUMMARY:\n",
            "==================================================\n",
            "\n",
            "POLLUTANT RANKING by Future PM Prediction Power:\n",
            "--------------------------------------------------\n",
            "  1. CARBON_MONOXIDE     : Avg=0.238, Max=0.496 - üü° TIER 2 (Moderate)\n",
            "  2. NH3                 : Avg=0.221, Max=0.388 - üü° TIER 2 (Moderate)\n",
            "  3. SULPHUR_DIOXIDE     : Avg=0.205, Max=0.380 - üü° TIER 2 (Moderate)\n",
            "  4. OZONE               : Avg=0.186, Max=0.430 - üü¢ TIER 3 (Weak)\n",
            "  5. NO                  : Avg=0.156, Max=0.213 - üü¢ TIER 3 (Weak)\n",
            "  6. NITROGEN_DIOXIDE    : Avg=0.147, Max=0.275 - üü¢ TIER 3 (Weak)\n"
          ]
        }
      ],
      "source": [
        "# 15.2 Detailed Pollutant ‚Üí Future PM Correlation Analysis\n",
        "if available_pollutants:\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"POLLUTANT ‚Üí FUTURE PM CORRELATION MATRIX\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    # Store all correlation results for comprehensive analysis\n",
        "    pollutant_predictive_power = {}\n",
        "    \n",
        "    for pollutant in available_pollutants:\n",
        "        print(f\"\\n{pollutant.upper()} ‚Üí FUTURE PM PREDICTION POWER:\")\n",
        "        print(\"-\" * 55)\n",
        "        \n",
        "        pollutant_predictive_power[pollutant] = {}\n",
        "        \n",
        "        for target in targets:\n",
        "            print(f\"\\n{pollutant.upper()} ‚Üí {target.upper()}:\")\n",
        "            print(f\"{'Horizon':<10} {'Correlation':<12} {'Predictive Power':<18} {'Assessment'}\")\n",
        "            print(\"-\" * 50)\n",
        "            \n",
        "            horizon_correlations = {}\n",
        "            \n",
        "            for horizon in prediction_horizons:\n",
        "                future_col = f'{target}_future_{horizon}h'\n",
        "                \n",
        "                if future_col in pollutant_future_df.columns and pollutant in pollutant_future_df.columns:\n",
        "                    # Calculate correlation between current pollutant and future PM\n",
        "                    corr = pollutant_future_df[pollutant].corr(pollutant_future_df[future_col])\n",
        "                    \n",
        "                    if not pd.isna(corr):\n",
        "                        horizon_correlations[horizon] = corr\n",
        "                        \n",
        "                        # Assess predictive power\n",
        "                        abs_corr = abs(corr)\n",
        "                        if abs_corr > 0.5:\n",
        "                            assessment = \"üî• STRONG predictor\"\n",
        "                        elif abs_corr > 0.3:\n",
        "                            assessment = \"üü° MODERATE predictor\"\n",
        "                        elif abs_corr > 0.2:\n",
        "                            assessment = \"üü¢ WEAK predictor\"\n",
        "                        elif abs_corr > 0.1:\n",
        "                            assessment = \"‚ö™ MINIMAL predictor\"\n",
        "                        else:\n",
        "                            assessment = \"‚ùå NEGLIGIBLE predictor\"\n",
        "                        \n",
        "                        # Format horizon display\n",
        "                        if horizon < 24:\n",
        "                            horizon_str = f\"{horizon}h\"\n",
        "                        else:\n",
        "                            days = horizon // 24\n",
        "                            remaining_hours = horizon % 24\n",
        "                            if remaining_hours == 0:\n",
        "                                horizon_str = f\"{days}d\"\n",
        "                            else:\n",
        "                                horizon_str = f\"{days}d{remaining_hours}h\"\n",
        "                        \n",
        "                        print(f\"{horizon_str:<10} {corr:>8.3f}    {abs_corr:>8.3f}          {assessment}\")\n",
        "                    else:\n",
        "                        horizon_correlations[horizon] = 0\n",
        "                        print(f\"{horizon}h:<10 {'N/A':<12} {'N/A':<18} ‚ùå Data issue\")\n",
        "                else:\n",
        "                    horizon_correlations[horizon] = 0\n",
        "                    print(f\"{horizon}h:<10 {'N/A':<12} {'N/A':<18} ‚ùå Missing data\")\n",
        "            \n",
        "            # Store results for this pollutant-target combination\n",
        "            pollutant_predictive_power[pollutant][target] = horizon_correlations\n",
        "            \n",
        "            # Summary for this pollutant-target combination\n",
        "            valid_corrs = [abs(corr) for corr in horizon_correlations.values() if corr != 0]\n",
        "            if valid_corrs:\n",
        "                max_corr = max(valid_corrs)\n",
        "                avg_corr = np.mean(valid_corrs)\n",
        "                \n",
        "                # Find best prediction horizon\n",
        "                best_horizon = max(horizon_correlations.items(), key=lambda x: abs(x[1]))[0]\n",
        "                best_corr = horizon_correlations[best_horizon]\n",
        "                \n",
        "                print(f\"\\n  üìä SUMMARY for {pollutant.upper()} ‚Üí {target.upper()}:\")\n",
        "                print(f\"    Best prediction horizon: {best_horizon}h (corr: {best_corr:.3f})\")\n",
        "                print(f\"    Max correlation: {max_corr:.3f}\")\n",
        "                print(f\"    Average correlation: {avg_corr:.3f}\")\n",
        "                \n",
        "                # Early warning capability assessment\n",
        "                if best_horizon <= 6 and max_corr > 0.3:\n",
        "                    print(f\"    ‚úÖ EXCELLENT early warning indicator (<6h, strong correlation)\")\n",
        "                elif best_horizon <= 12 and max_corr > 0.2:\n",
        "                    print(f\"    üü° GOOD early warning indicator (<12h, moderate correlation)\")\n",
        "                elif best_horizon <= 24 and max_corr > 0.1:\n",
        "                    print(f\"    üü¢ FAIR early warning indicator (<24h, weak correlation)\")\n",
        "                else:\n",
        "                    print(f\"    ‚ùå LIMITED early warning value\")\n",
        "    \n",
        "    print(f\"\\nüéØ POLLUTANT PREDICTIVE POWER SUMMARY:\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    # Rank pollutants by overall predictive power\n",
        "    pollutant_rankings = {}\n",
        "    \n",
        "    for pollutant in available_pollutants:\n",
        "        all_correlations = []\n",
        "        for target in targets:\n",
        "            if target in pollutant_predictive_power[pollutant]:\n",
        "                correlations = [abs(corr) for corr in pollutant_predictive_power[pollutant][target].values() if corr != 0]\n",
        "                all_correlations.extend(correlations)\n",
        "        \n",
        "        if all_correlations:\n",
        "            avg_predictive_power = np.mean(all_correlations)\n",
        "            max_predictive_power = max(all_correlations)\n",
        "            pollutant_rankings[pollutant] = {\n",
        "                'avg': avg_predictive_power,\n",
        "                'max': max_predictive_power\n",
        "            }\n",
        "    \n",
        "    # Sort by average predictive power\n",
        "    ranked_pollutants = sorted(pollutant_rankings.items(), key=lambda x: x[1]['avg'], reverse=True)\n",
        "    \n",
        "    print(f\"\\nPOLLUTANT RANKING by Future PM Prediction Power:\")\n",
        "    print(\"-\" * 50)\n",
        "    \n",
        "    for i, (pollutant, scores) in enumerate(ranked_pollutants, 1):\n",
        "        avg_score = scores['avg']\n",
        "        max_score = scores['max']\n",
        "        \n",
        "        if avg_score > 0.3:\n",
        "            tier = \"üî• TIER 1 (Strong)\"\n",
        "        elif avg_score > 0.2:\n",
        "            tier = \"üü° TIER 2 (Moderate)\"\n",
        "        elif avg_score > 0.1:\n",
        "            tier = \"üü¢ TIER 3 (Weak)\"\n",
        "        else:\n",
        "            tier = \"‚ùå TIER 4 (Negligible)\"\n",
        "        \n",
        "        print(f\"  {i}. {pollutant.upper():<20}: Avg={avg_score:.3f}, Max={max_score:.3f} - {tier}\")\n",
        "\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Cannot perform pollutant ‚Üí future PM analysis - no pollutants available\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 15.3 Pollutant vs Weather Predictive Power Comparison\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "POLLUTANTS vs WEATHER: FUTURE PM PREDICTION COMPARISON\n",
            "============================================================\n",
            "Comparing:\n",
            "‚Ä¢ 6 pollutants: ['carbon_monoxide', 'nitrogen_dioxide', 'ozone', 'sulphur_dioxide', 'no', 'nh3']\n",
            "‚Ä¢ 4 weather features: ['temperature', 'humidity', 'pressure', 'wind_speed']\n",
            "\n",
            "üìä PREDICTIVE POWER COMPARISON:\n",
            "==================================================\n",
            "\n",
            "PM2_5 PREDICTION - TOP PREDICTORS by Average Correlation:\n",
            "------------------------------------------------------------\n",
            "Rank Predictor                           Avg Correlation Type\n",
            "----------------------------------------------------------------------\n",
            "1    pressure                            0.370           üî• STRONG\n",
            "2    carbon_monoxide                     0.369           üî• STRONG\n",
            "3    nh3                                 0.291           üü° MODERATE\n",
            "4    ozone                               0.286           üü° MODERATE\n",
            "5    sulphur_dioxide                     0.235           üü° MODERATE\n",
            "6    nitrogen_dioxide                    0.229           üü° MODERATE\n",
            "7    wind_speed                          0.218           üü° MODERATE\n",
            "8    temperature                         0.173           üü¢ WEAK\n",
            "9    no                                  0.138           üü¢ WEAK\n",
            "10   humidity                            0.086           ‚ùå NEGLIGIBLE\n",
            "\n",
            "PM10 PREDICTION - TOP PREDICTORS by Average Correlation:\n",
            "------------------------------------------------------------\n",
            "Rank Predictor                           Avg Correlation Type\n",
            "----------------------------------------------------------------------\n",
            "1    sulphur_dioxide                     0.175           üü¢ WEAK\n",
            "2    no                                  0.174           üü¢ WEAK\n",
            "3    nh3                                 0.152           üü¢ WEAK\n",
            "4    temperature                         0.138           üü¢ WEAK\n",
            "5    wind_speed                          0.133           üü¢ WEAK\n",
            "6    carbon_monoxide                     0.106           üü¢ WEAK\n",
            "7    pressure                            0.102           üü¢ WEAK\n",
            "8    humidity                            0.088           ‚ùå NEGLIGIBLE\n",
            "9    ozone                               0.087           ‚ùå NEGLIGIBLE\n",
            "10   nitrogen_dioxide                    0.066           ‚ùå NEGLIGIBLE\n",
            "\n",
            "üéØ KEY INSIGHTS:\n",
            "==============================\n",
            "‚Ä¢ Strong pollutant predictors (>0.2 avg correlation): 5\n",
            "  ['ozone', 'nh3', 'sulphur_dioxide', 'carbon_monoxide', 'nitrogen_dioxide']\n",
            "‚Ä¢ Strong weather predictors (>0.2 avg correlation): 2\n",
            "  ['wind_speed', 'pressure']\n",
            "\n",
            "‚úÖ RECOMMENDATION: Pollutants are MORE IMPORTANT than weather for future PM prediction\n",
            "\n",
            "üìã MODELING IMPLICATIONS:\n",
            "‚Ä¢ Include both current pollutants AND weather for future PM prediction\n",
            "‚Ä¢ Pollutants provide chemical precursor information\n",
            "‚Ä¢ Weather provides atmospheric dispersion information\n",
            "‚Ä¢ Combined approach likely optimal for 72-hour forecasting\n"
          ]
        }
      ],
      "source": [
        "# 15.3 Compare Pollutants vs Weather for Future PM Prediction\n",
        "if available_pollutants:\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"POLLUTANTS vs WEATHER: FUTURE PM PREDICTION COMPARISON\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    # Weather features for comparison (same as Section 8.3)\n",
        "    weather_features = ['temperature', 'humidity', 'pressure', 'wind_speed']\n",
        "    available_weather = [col for col in weather_features if col in df.columns]\n",
        "    \n",
        "    print(f\"Comparing:\")\n",
        "    print(f\"‚Ä¢ {len(available_pollutants)} pollutants: {available_pollutants}\")\n",
        "    print(f\"‚Ä¢ {len(available_weather)} weather features: {available_weather}\")\n",
        "    \n",
        "    if available_weather:\n",
        "        # Calculate weather ‚Üí future PM correlations for comparison\n",
        "        weather_predictive_power = {}\n",
        "        \n",
        "        for weather_feature in available_weather:\n",
        "            weather_predictive_power[weather_feature] = {}\n",
        "            \n",
        "            for target in targets:\n",
        "                horizon_correlations = {}\n",
        "                \n",
        "                for horizon in prediction_horizons:\n",
        "                    future_col = f'{target}_future_{horizon}h'\n",
        "                    \n",
        "                    if future_col in pollutant_future_df.columns:\n",
        "                        # Calculate correlation between current weather and future PM\n",
        "                        corr = df[weather_feature].corr(pollutant_future_df[future_col])\n",
        "                        horizon_correlations[horizon] = corr if not pd.isna(corr) else 0\n",
        "                    else:\n",
        "                        horizon_correlations[horizon] = 0\n",
        "                \n",
        "                weather_predictive_power[weather_feature][target] = horizon_correlations\n",
        "        \n",
        "        # Compare predictive power: Pollutants vs Weather\n",
        "        print(f\"\\nüìä PREDICTIVE POWER COMPARISON:\")\n",
        "        print(\"=\" * 50)\n",
        "        \n",
        "        for target in targets:\n",
        "            print(f\"\\n{target.upper()} PREDICTION - TOP PREDICTORS by Average Correlation:\")\n",
        "            print(\"-\" * 60)\n",
        "            \n",
        "            # Collect all predictors (pollutants + weather)\n",
        "            all_predictors = {}\n",
        "            \n",
        "            # Add pollutant scores\n",
        "            for pollutant in available_pollutants:\n",
        "                if target in pollutant_predictive_power[pollutant]:\n",
        "                    correlations = [abs(corr) for corr in pollutant_predictive_power[pollutant][target].values() if corr != 0]\n",
        "                    if correlations:\n",
        "                        all_predictors[f\"{pollutant} (POLLUTANT)\"] = np.mean(correlations)\n",
        "            \n",
        "            # Add weather scores\n",
        "            for weather_feature in available_weather:\n",
        "                if target in weather_predictive_power[weather_feature]:\n",
        "                    correlations = [abs(corr) for corr in weather_predictive_power[weather_feature][target].values() if corr != 0]\n",
        "                    if correlations:\n",
        "                        all_predictors[f\"{weather_feature} (WEATHER)\"] = np.mean(correlations)\n",
        "            \n",
        "            # Sort by predictive power\n",
        "            sorted_predictors = sorted(all_predictors.items(), key=lambda x: x[1], reverse=True)\n",
        "            \n",
        "            print(f\"{'Rank':<4} {'Predictor':<35} {'Avg Correlation':<15} {'Type'}\")\n",
        "            print(\"-\" * 70)\n",
        "            \n",
        "            for i, (predictor, avg_corr) in enumerate(sorted_predictors, 1):\n",
        "                predictor_type = predictor.split('(')[1].replace(')', '')\n",
        "                predictor_name = predictor.split('(')[0].strip()\n",
        "                \n",
        "                if avg_corr > 0.3:\n",
        "                    strength = \"üî• STRONG\"\n",
        "                elif avg_corr > 0.2:\n",
        "                    strength = \"üü° MODERATE\"\n",
        "                elif avg_corr > 0.1:\n",
        "                    strength = \"üü¢ WEAK\"\n",
        "                else:\n",
        "                    strength = \"‚ùå NEGLIGIBLE\"\n",
        "                \n",
        "                print(f\"{i:<4} {predictor_name:<35} {avg_corr:<15.3f} {strength}\")\n",
        "        \n",
        "        # Summary insights\n",
        "        print(f\"\\nüéØ KEY INSIGHTS:\")\n",
        "        print(\"=\" * 30)\n",
        "        \n",
        "        # Count pollutants vs weather in top predictors\n",
        "        strong_pollutants = []\n",
        "        strong_weather = []\n",
        "        \n",
        "        for target in targets:\n",
        "            all_predictors = {}\n",
        "            \n",
        "            # Add pollutant scores\n",
        "            for pollutant in available_pollutants:\n",
        "                if target in pollutant_predictive_power[pollutant]:\n",
        "                    correlations = [abs(corr) for corr in pollutant_predictive_power[pollutant][target].values() if corr != 0]\n",
        "                    if correlations:\n",
        "                        avg_corr = np.mean(correlations)\n",
        "                        if avg_corr > 0.2:  # Strong threshold\n",
        "                            strong_pollutants.append(pollutant)\n",
        "            \n",
        "            # Add weather scores\n",
        "            for weather_feature in available_weather:\n",
        "                if target in weather_predictive_power[weather_feature]:\n",
        "                    correlations = [abs(corr) for corr in weather_predictive_power[weather_feature][target].values() if corr != 0]\n",
        "                    if correlations:\n",
        "                        avg_corr = np.mean(correlations)\n",
        "                        if avg_corr > 0.2:  # Strong threshold\n",
        "                            strong_weather.append(weather_feature)\n",
        "        \n",
        "        strong_pollutants = list(set(strong_pollutants))\n",
        "        strong_weather = list(set(strong_weather))\n",
        "        \n",
        "        print(f\"‚Ä¢ Strong pollutant predictors (>0.2 avg correlation): {len(strong_pollutants)}\")\n",
        "        if strong_pollutants:\n",
        "            print(f\"  {strong_pollutants}\")\n",
        "        \n",
        "        print(f\"‚Ä¢ Strong weather predictors (>0.2 avg correlation): {len(strong_weather)}\")\n",
        "        if strong_weather:\n",
        "            print(f\"  {strong_weather}\")\n",
        "        \n",
        "        # Recommendation\n",
        "        if len(strong_pollutants) > len(strong_weather):\n",
        "            print(f\"\\n‚úÖ RECOMMENDATION: Pollutants are MORE IMPORTANT than weather for future PM prediction\")\n",
        "        elif len(strong_weather) > len(strong_pollutants):\n",
        "            print(f\"\\n‚úÖ RECOMMENDATION: Weather is MORE IMPORTANT than pollutants for future PM prediction\")\n",
        "        else:\n",
        "            print(f\"\\n‚úÖ RECOMMENDATION: Pollutants and weather are EQUALLY IMPORTANT for future PM prediction\")\n",
        "        \n",
        "        print(f\"\\nüìã MODELING IMPLICATIONS:\")\n",
        "        print(f\"‚Ä¢ Include both current pollutants AND weather for future PM prediction\")\n",
        "        print(f\"‚Ä¢ Pollutants provide chemical precursor information\")\n",
        "        print(f\"‚Ä¢ Weather provides atmospheric dispersion information\")\n",
        "        print(f\"‚Ä¢ Combined approach likely optimal for 72-hour forecasting\")\n",
        "    \n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è No weather features available for comparison\")\n",
        "\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Cannot perform comparison - no pollutants available\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
